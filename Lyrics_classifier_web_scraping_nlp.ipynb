{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this project, we will build a text classification model on song lyrics. The task is to predict the artist from a piece of text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download a HTML page with links to songs\n",
    "\n",
    "- Extract hyperlinks of song pages\n",
    "\n",
    "- Download and extract the song lyrics\n",
    "\n",
    "- Vectorize the text using the Bag Of Words method\n",
    "\n",
    "- train a classification model that predicts the artist from a piece of text\n",
    "\n",
    "- refactor the code into functions\n",
    "\n",
    "- Write a simple command-line interface for the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  STEP1. WEB SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a HTML page with links to songs. To download web pages or send other HTTP requests in Python -->  requests module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests          #to download pages\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we get a 403, try this:\n",
    "#user_agent = {'User-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'}\n",
    "#source = requests.get(\"https://www.1001tracklists.com/\", headers=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_lyrics(url):\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    \n",
    "    #DOWNLOAD ARTIST URL AS TEXT FILE\n",
    "    response = requests.get(url,headers=headers)     #apply requests on my url\n",
    "    response.text      # this is the URL code\n",
    "    # save the string response_arcade.text to a newly created text file (in 'w'riting mode)\n",
    "    filename = 'arcade_fire.html'\n",
    "    open(filename, 'w', encoding = 'utf8').write(response.text)  #open :creates the file in writing mode\n",
    "    \n",
    "    #LOOK FOR ALL THE LINKS WITH REGULAR EXPRESIONS\n",
    "    links = re.findall('href=\"([^\"]+)\"', response.text)  #find everything that starts with href \n",
    "    \n",
    "    #CLEAN ALL THIS LINKS, WE WANT THE ONES THAT GO TO A LYRIC PAGE\n",
    "    links = [l for l in links if l.endswith('lyrics/') and l.startswith('http://www.songlyrics.com/')]\n",
    "    artist = links[0].split('/')[-3]  \n",
    "    links_final = [l for l in links if artist in l]\n",
    "    \n",
    "    #REMOVE DUPLICATED LINKS\n",
    "    all_songs=[]\n",
    "    for links in links_final:\n",
    "        song=links.split('/')[-2]\n",
    "        all_songs.append(song)\n",
    "        \n",
    "    links_cleaned = []\n",
    "    [links_cleaned.append(n) for n in links_final if n not in links_cleaned] \n",
    "    \n",
    "    lyrics = []\n",
    "    for url in links_final:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text)                #with soup, response.text now looks better\n",
    "        lyr = soup.find(id={\"songLyricsDiv-outer\"}).text   #in every HTML, find the first\"songLyricsDiv-outer\"\n",
    "        lyrics.append(lyr)\n",
    "        \n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcade_lyr = save_all_lyrics(\"http://www.songlyrics.com/arcade-fire-lyrics/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "impala_lyr = save_all_lyrics(\"http://www.songlyrics.com/tame-impala-lyrics/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns for y and X\n",
    "I have artists data separated, but I want to join them to only have one X and one Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = arcade_lyr\n",
    "X2 = impala_lyr\n",
    "\n",
    "arcade_artist = ['arcade_fire']             #create a list with 198 times \"arcade fire\"\n",
    "impala_artist = ['tame_impala']             #create a list with 140 times \"tame_impala\"\n",
    "\n",
    "y1 = 198*arcade_artist\n",
    "y2 = 140*impala_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 198, 140, 140)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X1), len(y1), len(X2), len(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, list, list)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X1), type(y1), type(X2), type(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I want to merge X1,X2 and y1,y2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedlist = []\n",
    "mergedlist.extend(arcade_lyr)\n",
    "mergedlist.extend(impala_lyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSaid the voice from afar,\\nDon't you know it doesn't\\nhave to be so hard? Waiting for\\neveryone else around to argee,\\nmight take too long\\n\\nWhen it won't be so hard,\\n(it won't be so hard)\\n\\nWell it's true,yes, but you\\nwont't get far telling me\\nthat you are all you're meant\\nto be, when the one from my\\ndream is sitting right next\\nto me and I don't know\\nwhat to do\\n\\nOh alter ego.\\n\\nGet them to love you,\\nwhile the may depending\\non your words and wealth,\\nthe only one who's really\\njudging you is yourself.\\nNobodyy else.\\n\\nIf I could part,\\nit wouldn't be so hard.\\n\\nWell it's true yes, but you\\nwon't get far telling me that\\nyou are all you're meant to\\nbe when the one from my\\ndream is sitting right next\\nto me and I don't know\\nwhat to do.\\n\\nOh alter ego.\\n\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedlist[100]    #---- lyrics from Arcade Fire\n",
    "mergedlist[197]    #---- lyrics from Arcade Fire - Intervention\n",
    "mergedlist[198]    #---- lyrics from Tame Impala - Alter Ego ----- Till the end all from Tame Impala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mergedlist)                         #it has to be 338!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_artist = []\n",
    "merged_artist.extend(y1)\n",
    "merged_artist.extend(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_artist = ['1' if artist == 'arcade_fire' else artist for artist in merged_artist]\n",
    "merged_artist = ['0' if artist == 'tame_impala' else artist for artist in merged_artist]\n",
    "merged_artist[197]      #0-197 is arcade fire (1)\n",
    "merged_artist[198]      #198-end is tame impala (0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338, 338)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_artist),  len(mergedlist)                    #same shape, perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mergedlist\n",
    "y = merged_artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2. Vectorize the text using the Bag Of Words method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Count Vectorizer (converting text into numbers):\n",
    "#### Steps to build\n",
    "* Create a corpus\n",
    "* Fit a CV on it - train the algorithm on all the language\n",
    "* Transform the corpus - for each document, turn it into a sparse, then dense, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<338x2926 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 23134 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "vectorized_lyr = cv.fit_transform(X)\n",
    "vectorized_lyr                             #now we have a 338x2926 SPARSE MATRIX\n",
    "#3386 rows = all the lyrics\n",
    "#2926 columns = all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_lyr[:5].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2926"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())     #2926 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_lyr_vectors = pd.DataFrame(vectorized_lyr.todense(), columns=cv.get_feature_names(), index=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11           1\n",
       "12           1\n",
       "12th         1\n",
       "13           3\n",
       "18           1\n",
       "            ..\n",
       "yours       34\n",
       "yourself     8\n",
       "zone         2\n",
       "écho         4\n",
       "él           1\n",
       "Length: 2926, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readable_lyr_vectors.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338, 2926)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readable_lyr_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#readable_lyr_vectors.sum(axis=1)            #row 1 has 380 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 2926 words, but we can reduce them using Tokenization, Stop words (and Normalizing the counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<338x2681 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13623 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '(?u)\\\\b\\\\w\\\\w+\\\\b' #all words or numbers with length >1    ----  2712\n",
    "b = '(?u)\\\\b\\\\w\\\\w*\\\\b' #all words or numbers of any length     ----  2695\n",
    "c = '(?u)\\\\b[a-zA-Z]+\\\\b' #only returns words, ignores all numbers and special characters    ----   2681\n",
    "cv = CountVectorizer(token_pattern=c, stop_words='english')\n",
    "vectorized_lyr = cv.fit_transform(X)\n",
    "vectorized_lyr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '(?u)\\\\b\\\\w\\\\w+\\\\b' #all words or numbers with length >1\n",
    "b = '(?u)\\\\b\\\\w\\\\w*\\\\b' #all words or numbers of any length\n",
    "c = '(?u)\\\\b[a-zA-Z]+\\\\b' #only returns words, ignores all numbers and special characters\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(token_pattern=c, stop_words='english')),   #CountVectorizer to transform the corpus into a matrix\n",
    "    ('tfidf', TfidfTransformer())                     #TfidTransformer to normalize the counts\n",
    "    ])\n",
    "#strip_accents='ascii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<338x2681 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13623 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_lyrics = pipeline.fit_transform(X)\n",
    "vectorized_lyrics                                         #the data has been reduced till 2681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readable_tf_vectors = pd.DataFrame(vectorized_lyrics.todense().round(2), columns=cv.get_feature_names(), index=y)\n",
    "type(readable_tf_vectors)\n",
    "\n",
    "#readable_lyr_vectors = pd.DataFrame(vectorized_lyr.todense(), columns=cv.get_feature_names(), index=X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaah</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absurd</th>\n",
       "      <th>accept</th>\n",
       "      <th>ache</th>\n",
       "      <th>aching</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yeux</th>\n",
       "      <th>yield</th>\n",
       "      <th>yo</th>\n",
       "      <th>yolk</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaaah  abandoned  abc  abraham  absurd  accept  ache  aching  act  acting  \\\n",
       "0   0.00        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0   0.00        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0   0.13        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0   0.00        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0   0.00        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0   0.00        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0   0.00        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0   0.00        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0   0.00        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0   0.00        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "\n",
       "   ...  yellow  yes  yesterday  yeux  yield   yo  yolk  young  youre  zone  \n",
       "0  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0  0.00  \n",
       "0  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0  0.00  \n",
       "0  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0  0.13  \n",
       "0  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0  0.00  \n",
       "0  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0  0.00  \n",
       "0  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0  0.00  \n",
       "0  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0  0.00  \n",
       "0  ...     0.0  0.0       0.11   0.0    0.0  0.0   0.0    0.0    0.0  0.00  \n",
       "0  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0  0.00  \n",
       "0  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0  0.00  \n",
       "\n",
       "[10 rows x 2681 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readable_tf_vectors.tail(10)       #we have til 2681 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaah',\n",
       " 'abandoned',\n",
       " 'abc',\n",
       " 'abraham',\n",
       " 'absurd',\n",
       " 'accept',\n",
       " 'ache',\n",
       " 'aching',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actors',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'address',\n",
       " 'adjust',\n",
       " 'administration',\n",
       " 'admit',\n",
       " 'adresss',\n",
       " 'adventure',\n",
       " 'advice',\n",
       " 'afar',\n",
       " 'affect',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'afterglow',\n",
       " 'afterlife',\n",
       " 'age',\n",
       " 'agenda',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhhhhhh',\n",
       " 'aid',\n",
       " 'aie',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airplane',\n",
       " 'aisle',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarme',\n",
       " 'alarms',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alice',\n",
       " 'alidocious',\n",
       " 'alive',\n",
       " 'allegiance',\n",
       " 'allies',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'alonzo',\n",
       " 'alors',\n",
       " 'aloud',\n",
       " 'alright',\n",
       " 'alter',\n",
       " 'alzheimer',\n",
       " 'amazing',\n",
       " 'amber',\n",
       " 'ambulances',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ancient',\n",
       " 'angel',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'annee',\n",
       " 'annihilate',\n",
       " 'announcer',\n",
       " 'answer',\n",
       " 'answers',\n",
       " 'anthem',\n",
       " 'antiaircraft',\n",
       " 'antichrist',\n",
       " 'anticipation',\n",
       " 'antoinish',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'apart',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'approaching',\n",
       " 'arc',\n",
       " 'arcade',\n",
       " 'aren',\n",
       " 'argee',\n",
       " 'arise',\n",
       " 'arm',\n",
       " 'armageddon',\n",
       " 'armee',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arrete',\n",
       " 'arrive',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'ascend',\n",
       " 'ashes',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'ass',\n",
       " 'assisted',\n",
       " 'association',\n",
       " 'assumed',\n",
       " 'astray',\n",
       " 'atlantic',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attend',\n",
       " 'attends',\n",
       " 'attic',\n",
       " 'aurore',\n",
       " 'autobahn',\n",
       " 'autobiography',\n",
       " 'autre',\n",
       " 'autumn',\n",
       " 'avec',\n",
       " 'aw',\n",
       " 'awake',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awful',\n",
       " 'awoke',\n",
       " 'babe',\n",
       " 'babes',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'backed',\n",
       " 'backseat',\n",
       " 'backwards',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bags',\n",
       " 'bah',\n",
       " 'banal',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'bang',\n",
       " 'banished',\n",
       " 'banter',\n",
       " 'barely',\n",
       " 'barricade',\n",
       " 'bashful',\n",
       " 'bathroom',\n",
       " 'bathtub',\n",
       " 'batman',\n",
       " 'battle',\n",
       " 'beach',\n",
       " 'bearing',\n",
       " 'bears',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'bedrooms',\n",
       " 'began',\n",
       " 'begger',\n",
       " 'begging',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begun',\n",
       " 'beings',\n",
       " 'believe',\n",
       " 'believes',\n",
       " 'believing',\n",
       " 'belittlin',\n",
       " 'bell',\n",
       " 'bells',\n",
       " 'belong',\n",
       " 'bend',\n",
       " 'bending',\n",
       " 'beneath',\n",
       " 'benjis',\n",
       " 'berlin',\n",
       " 'berry',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'betrayed',\n",
       " 'betta',\n",
       " 'better',\n",
       " 'bias',\n",
       " 'bible',\n",
       " 'bicycle',\n",
       " 'bide',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'bikes',\n",
       " 'bikini',\n",
       " 'billion',\n",
       " 'bills',\n",
       " 'bin',\n",
       " 'bind',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birth',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bits',\n",
       " 'biz',\n",
       " 'bizarre',\n",
       " 'black',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'bleed',\n",
       " 'bleeding',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessing',\n",
       " 'blew',\n",
       " 'blinded',\n",
       " 'blindfold',\n",
       " 'blindness',\n",
       " 'blink',\n",
       " 'bliss',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'bloomed',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blows',\n",
       " 'blue',\n",
       " 'board',\n",
       " 'boarded',\n",
       " 'boast',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'boil',\n",
       " 'boldly',\n",
       " 'bolt',\n",
       " 'bolts',\n",
       " 'bomb',\n",
       " 'bomba',\n",
       " 'bombs',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'books',\n",
       " 'boom',\n",
       " 'boomers',\n",
       " 'border',\n",
       " 'bored',\n",
       " 'born',\n",
       " 'boss',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'bovell',\n",
       " 'bow',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'bragadocious',\n",
       " 'brain',\n",
       " 'brains',\n",
       " 'brand',\n",
       " 'bravery',\n",
       " 'brazil',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathin',\n",
       " 'breathing',\n",
       " 'brick',\n",
       " 'bridge',\n",
       " 'bridges',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'broad',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'bruce',\n",
       " 'brutal',\n",
       " 'buckwild',\n",
       " 'buddy',\n",
       " 'build',\n",
       " 'building',\n",
       " 'buildings',\n",
       " 'built',\n",
       " 'bullshit',\n",
       " 'buries',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burns',\n",
       " 'burp',\n",
       " 'bury',\n",
       " 'bus',\n",
       " 'buses',\n",
       " 'bush',\n",
       " 'businessmen',\n",
       " 'bust',\n",
       " 'butkas',\n",
       " 'butler',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buys',\n",
       " 'bye',\n",
       " 'c',\n",
       " 'cabeza',\n",
       " 'cadillac',\n",
       " 'cage',\n",
       " 'calf',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camera',\n",
       " 'cancer',\n",
       " 'candle',\n",
       " 'candy',\n",
       " 'canyons',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'care',\n",
       " 'cared',\n",
       " 'cares',\n",
       " 'carry',\n",
       " 'cars',\n",
       " 'carved',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'casse',\n",
       " 'cast',\n",
       " 'casts',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'causin',\n",
       " 'ce',\n",
       " 'cell',\n",
       " 'cellphone',\n",
       " 'cement',\n",
       " 'century',\n",
       " 'certain',\n",
       " 'cha',\n",
       " 'chance',\n",
       " 'chancer',\n",
       " 'chances',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changin',\n",
       " 'changing',\n",
       " 'charm',\n",
       " 'charms',\n",
       " 'chassagne',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checkin',\n",
       " 'cheers',\n",
       " 'chemistry',\n",
       " 'cheney',\n",
       " 'cheval',\n",
       " 'chewy',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chickens',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chimed',\n",
       " 'chimney',\n",
       " 'chip',\n",
       " 'choice',\n",
       " 'choking',\n",
       " 'chooey',\n",
       " 'choose',\n",
       " 'chorus',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'christ',\n",
       " 'christean',\n",
       " 'christian',\n",
       " 'chub',\n",
       " 'church',\n",
       " 'circles',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'clap',\n",
       " 'claude',\n",
       " 'clean',\n",
       " 'cleaners',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'clearly',\n",
       " 'click',\n",
       " 'climb',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'closing',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clouds',\n",
       " 'clues',\n",
       " 'clung',\n",
       " 'coalition',\n",
       " 'coals',\n",
       " 'coast',\n",
       " 'cockroach',\n",
       " 'cocoa',\n",
       " 'coerce',\n",
       " 'cold',\n",
       " 'colder',\n",
       " 'collapsing',\n",
       " 'collar',\n",
       " 'colors',\n",
       " 'colours',\n",
       " 'combed',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comin',\n",
       " 'coming',\n",
       " 'comme',\n",
       " 'commences',\n",
       " 'commentators',\n",
       " 'commerce',\n",
       " 'commit',\n",
       " 'committed',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compete',\n",
       " 'competing',\n",
       " 'completely',\n",
       " 'composure',\n",
       " 'compressed',\n",
       " 'concentrate',\n",
       " 'concern',\n",
       " 'concur',\n",
       " 'condom',\n",
       " 'confused',\n",
       " 'confusing',\n",
       " 'connected',\n",
       " 'connector',\n",
       " 'conscience',\n",
       " 'conscious',\n",
       " 'consumes',\n",
       " 'content',\n",
       " 'continued',\n",
       " 'contrary',\n",
       " 'control',\n",
       " 'conveniently',\n",
       " 'convince',\n",
       " 'cool',\n",
       " 'cops',\n",
       " 'corner',\n",
       " 'corruption',\n",
       " 'cosas',\n",
       " 'cost',\n",
       " 'cotton',\n",
       " 'couldn',\n",
       " 'count',\n",
       " 'counted',\n",
       " 'counting',\n",
       " 'country',\n",
       " 'countryside',\n",
       " 'course',\n",
       " 'couse',\n",
       " 'cousins',\n",
       " 'cover',\n",
       " 'covered',\n",
       " 'covers',\n",
       " 'cracks',\n",
       " 'crash',\n",
       " 'crashing',\n",
       " 'crawling',\n",
       " 'crazy',\n",
       " 'creature',\n",
       " 'creepin',\n",
       " 'crickets',\n",
       " 'cried',\n",
       " 'cries',\n",
       " 'crime',\n",
       " 'crisco',\n",
       " 'crisis',\n",
       " 'crois',\n",
       " 'cross',\n",
       " 'crouched',\n",
       " 'crowd',\n",
       " 'crown',\n",
       " 'crucified',\n",
       " 'cruel',\n",
       " 'crunch',\n",
       " 'crying',\n",
       " 'crystallize',\n",
       " 'cuban',\n",
       " 'cuffed',\n",
       " 'cultivate',\n",
       " 'cup',\n",
       " 'cure',\n",
       " 'curse',\n",
       " 'curved',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutting',\n",
       " 'cynical',\n",
       " 'd',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'dagger',\n",
       " 'daggers',\n",
       " 'daily',\n",
       " 'daisy',\n",
       " 'dallas',\n",
       " 'dally',\n",
       " 'damage',\n",
       " 'damian',\n",
       " 'damien',\n",
       " 'damme',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'danza',\n",
       " 'dare',\n",
       " 'dared',\n",
       " 'darest',\n",
       " 'daring',\n",
       " 'dark',\n",
       " 'darkest',\n",
       " 'darkness',\n",
       " 'darling',\n",
       " 'dating',\n",
       " 'daughter',\n",
       " 'daughters',\n",
       " 'dawns',\n",
       " 'day',\n",
       " 'daylight',\n",
       " 'days',\n",
       " 'daytime',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'deathbed',\n",
       " 'debt',\n",
       " 'debts',\n",
       " 'deceide',\n",
       " 'deceive',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decipher',\n",
       " 'decision',\n",
       " 'decisions',\n",
       " 'deck',\n",
       " 'deckin',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'deer',\n",
       " 'defeat',\n",
       " 'defend',\n",
       " 'defender',\n",
       " 'deflate',\n",
       " 'deflected',\n",
       " 'defy',\n",
       " 'democratic',\n",
       " 'demons',\n",
       " 'dennis',\n",
       " 'deny',\n",
       " 'denzel',\n",
       " 'depending',\n",
       " 'deprived',\n",
       " 'depth',\n",
       " 'depths',\n",
       " 'des',\n",
       " 'deserted',\n",
       " 'deserve',\n",
       " 'desire',\n",
       " 'desperately',\n",
       " 'desperation',\n",
       " 'despise',\n",
       " 'destruction',\n",
       " 'deuce',\n",
       " 'deux',\n",
       " 'diamond',\n",
       " 'diamonds',\n",
       " 'dick',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'die',\n",
       " 'died',\n",
       " 'dies',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'dig',\n",
       " 'digest',\n",
       " 'digital',\n",
       " 'dilly',\n",
       " 'dim',\n",
       " 'dimensions',\n",
       " 'ding',\n",
       " 'dip',\n",
       " 'direction',\n",
       " 'dirt',\n",
       " 'dis',\n",
       " 'disagree',\n",
       " 'disappear',\n",
       " 'disappeared',\n",
       " 'disappointed',\n",
       " 'disarm',\n",
       " 'disco',\n",
       " 'disconnect',\n",
       " 'discover',\n",
       " 'discs',\n",
       " 'disease',\n",
       " 'dissatisfied',\n",
       " 'dissolved',\n",
       " 'distance',\n",
       " 'distant',\n",
       " 'divert',\n",
       " 'divides',\n",
       " 'divin',\n",
       " 'divorce',\n",
       " 'divorces',\n",
       " 'dobailina',\n",
       " 'doc',\n",
       " 'doctor',\n",
       " 'doe',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'doggin',\n",
       " 'doing',\n",
       " 'dollar',\n",
       " 'dollars',\n",
       " 'don',\n",
       " 'doomed',\n",
       " 'door',\n",
       " 'doors',\n",
       " 'doorway',\n",
       " 'dosey',\n",
       " 'dotted',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'doubts',\n",
       " 'doulbe',\n",
       " 'douse',\n",
       " 'dover',\n",
       " 'downtown',\n",
       " 'drafted',\n",
       " 'dragging',\n",
       " 'drain',\n",
       " 'draws',\n",
       " 'dream',\n",
       " 'dreaming',\n",
       " 'dreams',\n",
       " 'dreamt',\n",
       " 'dressed',\n",
       " 'drift',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'driver',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'dropping',\n",
       " 'drove',\n",
       " 'drown',\n",
       " 'drowned',\n",
       " 'drums',\n",
       " 'drunk',\n",
       " 'dry',\n",
       " 'dukes',\n",
       " 'dumpty',\n",
       " 'dunna',\n",
       " 'dunno',\n",
       " 'dust',\n",
       " 'duty',\n",
       " 'duvalier',\n",
       " 'dwarves',\n",
       " 'dyin',\n",
       " 'dying',\n",
       " 'eachother',\n",
       " 'ear',\n",
       " 'early',\n",
       " 'earned',\n",
       " 'earplugs',\n",
       " 'ears',\n",
       " 'earth',\n",
       " 'earthquake',\n",
       " 'earthquakes',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'eau',\n",
       " 'echo',\n",
       " 'eclairent',\n",
       " 'eclipse',\n",
       " 'economic',\n",
       " 'edging',\n",
       " 'educated',\n",
       " 'effect',\n",
       " 'egg',\n",
       " 'ego',\n",
       " 'eh',\n",
       " 'eighties',\n",
       " 'election',\n",
       " 'electric',\n",
       " 'elephant',\n",
       " 'elodie',\n",
       " 'elope',\n",
       " 'em',\n",
       " 'embarrassing',\n",
       " 'embers',\n",
       " 'emcees',\n",
       " 'emotion',\n",
       " 'emotions',\n",
       " 'emperor',\n",
       " 'enacted',\n",
       " 'encore',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'endless',\n",
       " 'endlessly',\n",
       " 'ends',\n",
       " 'enemy',\n",
       " 'enfants',\n",
       " 'engine',\n",
       " 'english',\n",
       " 'enraged',\n",
       " 'entends',\n",
       " 'enter',\n",
       " 'entertaining',\n",
       " 'entire',\n",
       " 'entre',\n",
       " 'envelope',\n",
       " 'equipped',\n",
       " 'erase',\n",
       " 'erasing',\n",
       " 'es',\n",
       " 'escape',\n",
       " 'escapes',\n",
       " 'eso',\n",
       " 'espirits',\n",
       " 'est',\n",
       " 'et',\n",
       " 'ether',\n",
       " 'eurydice',\n",
       " 'eve',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'eventually',\n",
       " 'everybody',\n",
       " 'everyday',\n",
       " 'everytime',\n",
       " 'evil',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'excited',\n",
       " 'exist',\n",
       " 'expectation',\n",
       " 'experiments',\n",
       " 'explain',\n",
       " 'explode',\n",
       " 'extension',\n",
       " 'eye',\n",
       " 'eyelids',\n",
       " 'eyes',\n",
       " 'f',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'facing',\n",
       " 'fact',\n",
       " 'facts',\n",
       " 'fade',\n",
       " 'fades',\n",
       " 'fading',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'failing',\n",
       " 'fails',\n",
       " 'fair',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'fallen',\n",
       " 'fallin',\n",
       " 'falling',\n",
       " 'falls',\n",
       " 'fame',\n",
       " 'familiar',\n",
       " 'famille',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'far',\n",
       " 'farms',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'fate',\n",
       " 'father',\n",
       " 'fathers',\n",
       " 'fault',\n",
       " 'favors',\n",
       " 'favours',\n",
       " 'faygo',\n",
       " 'fear',\n",
       " 'fearing',\n",
       " 'fears',\n",
       " 'feather',\n",
       " 'fee',\n",
       " 'feed',\n",
       " 'feedback',\n",
       " 'feeds',\n",
       " 'feel',\n",
       " 'feelin',\n",
       " 'feeling',\n",
       " 'feelings',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'fell',\n",
       " 'felt',\n",
       " 'fence',\n",
       " 'field',\n",
       " 'figaro',\n",
       " 'fight',\n",
       " 'fighter',\n",
       " 'fightin',\n",
       " 'fighting',\n",
       " 'figure',\n",
       " 'filled',\n",
       " 'fills',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'fine',\n",
       " 'finest',\n",
       " 'fingers',\n",
       " 'fires',\n",
       " 'fix',\n",
       " 'fizzle',\n",
       " 'flag',\n",
       " 'flame',\n",
       " 'flames',\n",
       " 'flash',\n",
       " 'flashbulb',\n",
       " 'flashing',\n",
       " 'flesh',\n",
       " 'flick',\n",
       " 'flight',\n",
       " 'flinstone',\n",
       " 'flip',\n",
       " 'float',\n",
       " 'floor',\n",
       " 'flow',\n",
       " 'flowers',\n",
       " 'flows',\n",
       " 'fluctuation',\n",
       " 'fluctuations',\n",
       " 'flutterin',\n",
       " 'fly',\n",
       " 'flyin',\n",
       " 'flying',\n",
       " 'fold',\n",
       " 'folded',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'food',\n",
       " 'fooey',\n",
       " 'fool',\n",
       " 'fooled',\n",
       " 'foolin',\n",
       " 'fools',\n",
       " 'footsteps',\n",
       " 'force',\n",
       " 'forehead',\n",
       " 'foreign',\n",
       " 'forest',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgets',\n",
       " 'forgetting',\n",
       " 'forgive',\n",
       " 'forgiven',\n",
       " 'forgivin',\n",
       " 'forgot',\n",
       " 'forgotten',\n",
       " 'formation',\n",
       " 'formative',\n",
       " 'forment',\n",
       " 'forth',\n",
       " 'fought',\n",
       " 'francisco',\n",
       " 'freaky',\n",
       " 'free',\n",
       " 'freeway',\n",
       " 'fresh',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'frolic',\n",
       " 'frozen',\n",
       " 'fruity',\n",
       " 'fryin',\n",
       " 'ft',\n",
       " 'fu',\n",
       " 'fuck',\n",
       " 'fucked',\n",
       " 'fuckin',\n",
       " 'fucking',\n",
       " 'fun',\n",
       " 'funky',\n",
       " 'funny',\n",
       " 'furnish',\n",
       " 'future',\n",
       " 'g',\n",
       " 'gained',\n",
       " 'game',\n",
       " 'games',\n",
       " 'garden',\n",
       " 'gas',\n",
       " 'gasoline',\n",
       " 'gassed',\n",
       " 'gate',\n",
       " 'gauge',\n",
       " 'gave',\n",
       " 'gazing',\n",
       " 'generation',\n",
       " 'gentlemen',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'ghetto',\n",
       " 'ghost',\n",
       " 'giants',\n",
       " 'girl',\n",
       " 'girls',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'glass',\n",
       " 'glassing',\n",
       " 'glimpse',\n",
       " 'global',\n",
       " 'glock',\n",
       " 'glory',\n",
       " 'glowin',\n",
       " 'glued',\n",
       " 'goal',\n",
       " 'god',\n",
       " 'gods',\n",
       " 'goes',\n",
       " 'goin',\n",
       " 'going',\n",
       " 'gold',\n",
       " 'golden',\n",
       " 'golly',\n",
       " 'gon',\n",
       " 'gone',\n",
       " 'gonna',\n",
       " 'gonzales',\n",
       " 'good',\n",
       " 'goodbye',\n",
       " 'goodbyes',\n",
       " 'goodness',\n",
       " 'goodnight',\n",
       " 'goofed',\n",
       " 'gorgeous',\n",
       " 'got',\n",
       " 'gots',\n",
       " 'gotta',\n",
       " 'government',\n",
       " 'governor',\n",
       " 'goya',\n",
       " 'grab',\n",
       " 'grabbed',\n",
       " 'grace',\n",
       " 'gradually',\n",
       " 'grand',\n",
       " 'grass',\n",
       " 'grave',\n",
       " 'graves',\n",
       " ...]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFTER THE PIPELINE, WE HAVE REDUCED OUR DATA AND TRANSFORMED AS A DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaah</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absurd</th>\n",
       "      <th>accept</th>\n",
       "      <th>ache</th>\n",
       "      <th>aching</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yeux</th>\n",
       "      <th>yield</th>\n",
       "      <th>yo</th>\n",
       "      <th>yolk</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 2681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aaaah  abandoned  abc  abraham  absurd  accept  ache  aching  act  acting  \\\n",
       "1     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "1     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "1     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "1     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "1     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "..    ...        ...  ...      ...     ...     ...   ...     ...  ...     ...   \n",
       "0     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "0     0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0     0.0   \n",
       "\n",
       "    ...  yellow  yes  yesterday  yeux  yield   yo  yolk  young  youre  zone  \n",
       "1   ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "1   ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "1   ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "1   ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "1   ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "..  ...     ...  ...        ...   ...    ...  ...   ...    ...    ...   ...  \n",
       "0   ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "0   ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "0   ...     0.0  0.0       0.11   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "0   ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "0   ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "\n",
       "[338 rows x 2681 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readable_tf_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_tf_vectors = readable_tf_vectors.reset_index()\n",
    "readable_tf_vectors = readable_tf_vectors.rename(columns={'index': 'artist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(readable_tf_vectors)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absurd</th>\n",
       "      <th>accept</th>\n",
       "      <th>ache</th>\n",
       "      <th>aching</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yeux</th>\n",
       "      <th>yield</th>\n",
       "      <th>yo</th>\n",
       "      <th>yolk</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 2682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist  aaaah  abandoned  abc  abraham  absurd  accept  ache  aching  act  \\\n",
       "0        1    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "1        1    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "2        1    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "3        1    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "4        1    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "..     ...    ...        ...  ...      ...     ...     ...   ...     ...  ...   \n",
       "333      0    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "334      0    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "335      0    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "336      0    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "337      0    0.0        0.0  0.0      0.0     0.0     0.0   0.0     0.0  0.0   \n",
       "\n",
       "     ...  yellow  yes  yesterday  yeux  yield   yo  yolk  young  youre  zone  \n",
       "0    ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "1    ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "2    ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "3    ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "4    ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "..   ...     ...  ...        ...   ...    ...  ...   ...    ...    ...   ...  \n",
       "333  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "334  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "335  ...     0.0  0.0       0.11   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "336  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "337  ...     0.0  0.0       0.00   0.0    0.0  0.0   0.0    0.0    0.0   0.0  \n",
       "\n",
       "[338 rows x 2682 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(readable_tf_vectors)                   #convert to DF\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'artist']\n",
    "y = df['artist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3. Train a classification model that predicts the artist from a piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253, 2681), (85, 2681))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression() #initialize the model\n",
    "model.fit(X_train, y_train)   # trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing your model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cross-validation mean 0.866 +- 0.031'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "cv_all = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "cv_mean = cv_all.mean()\n",
    "cv_std = np.std(cv_all)\n",
    "f\"Cross-validation mean {cv_mean:5.3f} +- {cv_std:5.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8656923076923076"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03102241983702076"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "# Lets visualise a distribution of the results\n",
    "plt.bar(range(10), cv_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9407114624505929"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "train_score = model.score(X_train, y_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is the score inside the range?\n",
    "train_score > cv_all.min() and train_score < cv_all.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is the score is inside one sigma?\n",
    "train_score - cv_mean < cv_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9176470588235294"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = model.score(X_test, y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70588235, 0.74509804, 0.68627451, 0.74      , 0.7       ])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "m = RandomForestClassifier(n_estimators=20, max_depth=2)\n",
    "cross_val_score(m, X_train, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8063241106719368"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X_train, y_train)\n",
    "m.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
